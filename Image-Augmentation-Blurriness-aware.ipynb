{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depths.csv', 'sample_submission.csv', 'test.zip', 'train', 'train.csv', 'train.zip', 'train_crop']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "print(os.listdir(\"data_aug\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurAwareCrop():\n",
    "    def __init__(self, prob=0.7, blur_thres=200, min_crop=20, return_size=50):\n",
    "        self.prob = prob\n",
    "        self.blur_thres = blur_thres\n",
    "        self.min_crop = min_crop\n",
    "        self.return_size = return_size\n",
    "        self.tr = None\n",
    "    \n",
    "    # reference: https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "    def sharp_measure(self, img_pil):\n",
    "        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "        return cv2.Laplacian(img_cv, cv2.CV_64F).var()\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        '''\n",
    "        if given image has RGB mode(salt image), compute the sharpness of image using cv and setup transforms to be applied\n",
    "        otherwise, if mask is given, just applies same transform again.\n",
    "        '''\n",
    "        if img.mode == 'RGB':\n",
    "            if self.sharp_measure(img) > self.blur_thres and np.random.rand() < self.prob:\n",
    "                crop_size = np.random.randint(self.min_crop, self.return_size)\n",
    "                self.tr = transforms.Compose([\n",
    "                    transforms.RandomCrop(crop_size),\n",
    "                    transforms.Resize(self.return_size)\n",
    "                ])\n",
    "            else:\n",
    "                self.tr = transforms.Compose([])\n",
    "        return self.tr(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = BlurAwareCrop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = pd.read_csv('data/train.csv', usecols=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(index):\n",
    "    img = Image.open(f'data/train/images/{fnames.id[index]}.png')\n",
    "    mask = Image.open(f'data/train/masks/{fnames.id[index]}.png')\n",
    "    sharpness = tr.sharp_measure(img)\n",
    "    print(f\"image sharpness: {sharpness}\")\n",
    "    if sharpness > tr.blur_thres:\n",
    "        print(f\"image is sharp enough, cropping is applied with probability {tr.prob}\")\n",
    "    else:\n",
    "        print(\"image is blurry, cropping will not applied\")\n",
    "    \n",
    "    plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    plt.subplot(141)\n",
    "    plt.title('image before transform')\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.subplot(142)\n",
    "    plt.title('mask before transform')\n",
    "    plt.imshow(mask)\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.title('image after transform')\n",
    "    plt.imshow(tr(img))\n",
    "    \n",
    "    plt.subplot(144)\n",
    "    plt.title('mask after transform')\n",
    "    plt.imshow(tr(mask))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image():\n",
    "    if not os.path.exists('data_aug/train/images_blurriness/'):\n",
    "        os.makedirs('data_aug/train/images_blurriness/')\n",
    "    if not os.path.exists('data_aug/train/masks_blurriness/'):\n",
    "        os.makedirs('data_aug/train/masks_blurriness/')\n",
    "    for fname in fnames.id:\n",
    "        img = Image.open(f'data/train/images/{fname}.png')\n",
    "        mask = Image.open(f'data/train/masks/{fname}.png')\n",
    "\n",
    "        tr(img).save(f'data_aug/train/images_blurriness/{fname}.png')\n",
    "        tr(mask).save(f'data_aug/train/masks_blurriness/{fname}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_crop():\n",
    "    if not os.path.exists('data_aug/train_crop/images_blurriness/'):\n",
    "        os.makedirs('data_aug/train_crop/images_blurriness/')\n",
    "    if not os.path.exists('data_aug/train_crop/masks_blurriness/'):\n",
    "        os.makedirs('data_aug/train_crop/masks_blurriness/')\n",
    "    for fname in fnames.id:\n",
    "        imgLeftUpper = Image.open(f'data_aug/train_crop/images/{fname}-leftUpper.png')\n",
    "        maskLeftUpper = Image.open(f'data_aug/train_crop/masks/{fname}-leftUpper.png')\n",
    "        imgLeftBottom = Image.open(f'data_aug/train_crop/images/{fname}-leftBottom.png')\n",
    "        maskLeftBottom = Image.open(f'data_aug/train_crop/masks/{fname}-leftBottom.png')\n",
    "        imgRightUpper = Image.open(f'data_aug/train_crop/images/{fname}-rightUpper.png')\n",
    "        maskRightUpper = Image.open(f'data_aug/train_crop/masks/{fname}-rightUpper.png')\n",
    "        imgRightBottom = Image.open(f'data_aug/train_crop/images/{fname}-rightBottom.png')\n",
    "        maskRightBottom = Image.open(f'data_aug/train_crop/masks/{fname}-rightBottom.png')\n",
    "\n",
    "        tr(imgLeftUpper).save(f'data_aug/train_crop/images_blurriness/{fname}-leftUpper.png')\n",
    "        tr(maskLeftUpper).save(f'data_aug/train_crop/masks_blurriness/{fname}-leftUpper.png')\n",
    "        tr(imgLeftBottom).save(f'data_aug/train_crop/images_blurriness/{fname}-leftBottom.png')\n",
    "        tr(maskLeftBottom).save(f'data_aug/train_crop/masks_blurriness/{fname}-leftBottom.png')\n",
    "        tr(imgRightUpper).save(f'data_aug/train_crop/images_blurriness/{fname}-rightUpper.png')\n",
    "        tr(maskRightUpper).save(f'data_aug/train_crop/masks_blurriness/{fname}-rightUpper.png')\n",
    "        tr(imgRightBottom).save(f'data_aug/train_crop/images_blurriness/{fname}-rightBottom.png')\n",
    "        tr(maskRightBottom).save(f'data_aug/train_crop/masks_blurriness/{fname}-rightBottom.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
